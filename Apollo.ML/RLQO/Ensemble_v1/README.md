# Ensemble v1: Voting Ensemble for Query Optimization

## ê°œìš”

4ê°œì˜ ê°•í™”í•™ìŠµ ëª¨ë¸(DQN v3, PPO v3, DDPG v1, SAC v1)ì„ ê²°í•©í•˜ëŠ” Voting Ensembleì„ êµ¬í˜„í•˜ì—¬ ì¿¼ë¦¬ ìµœì í™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

## ëª¨ë¸ êµ¬ì„±

### ì‚¬ìš© ëª¨ë¸

1. **DQN v3** (Discrete Action Space)
   - Deep Q-Network
   - ê°œë³„ ì•¡ì…˜ ì„ íƒì— íŠ¹í™”
   - Mean Speedup: ~1.15x

2. **PPO v3** (Discrete Action Space with Masking)
   - Proximal Policy Optimization
   - ì•ˆì „í•œ ì•¡ì…˜ ì„ íƒ (ì•¡ì…˜ ë§ˆìŠ¤í‚¹)
   - Mean Speedup: ~1.20x
   - CTE ì¿¼ë¦¬ì— ê°•ì 

3. **DDPG v1** (Continuous Action Space)
   - Deep Deterministic Policy Gradient
   - ë‹¤ì¤‘ ì•¡ì…˜ ì¡°í•© ê°€ëŠ¥
   - Mean Speedup: ~1.88x (ìµœê³  ì„±ëŠ¥)
   - JOIN_HEAVY ì¿¼ë¦¬ì— ê°•ì 

4. **SAC v1** (Continuous Action Space)
   - Soft Actor-Critic
   - Maximum Entropyë¡œ íƒìƒ‰ ê°•í™”
   - Mean Speedup: ~1.50x (ì¶”ì •)

## íˆ¬í‘œ ì „ëµ

### 1. Majority Voting
- ê°€ì¥ ë§ì´ ì„ íƒëœ ì•¡ì…˜ ì„ íƒ
- ë‹¨ìˆœí•˜ê³  ê²¬ê³ í•¨

### 2. Weighted Voting
- Confidence scoreë¡œ ê°€ì¤‘ì¹˜ ë¶€ì—¬
- ê° ëª¨ë¸ì˜ í™•ì‹ ë„ ê³ ë ¤

### 3. Equal Weighted
- ëª¨ë“  ëª¨ë¸ì— ë™ì¼í•œ ê°€ì¤‘ì¹˜
- ê³µì •í•œ íˆ¬í‘œ

### 4. Performance-Based
- ëª¨ë¸ì˜ í‰ê·  ì„±ëŠ¥ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì„¤ì •
- DDPG > SAC > PPO > DQN ìˆœì„œ

### 5. Query Type-Based
- ì¿¼ë¦¬ íƒ€ì…ë³„ë¡œ ìµœì  ëª¨ë¸ì— ë†’ì€ ê°€ì¤‘ì¹˜
- CTE â†’ PPO, JOIN_HEAVY â†’ DDPG ë“±

## ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
Ensemble_v1/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ensemble_config.py          # ì„¤ì • (ëª¨ë¸ ê²½ë¡œ, ê°€ì¤‘ì¹˜)
â”œâ”€â”€ env/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ensemble_env.py              # í™˜ê²½ ë˜í¼
â”œâ”€â”€ ensemble_voting.py               # í•µì‹¬ Voting Ensemble í´ë˜ìŠ¤
â”œâ”€â”€ voting_strategies.py             # íˆ¬í‘œ ì „ëµ í•¨ìˆ˜ë“¤
â”œâ”€â”€ visualize_ensemble.py            # ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ensemble_evaluate.py        # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ ensemble_voting_results.json
â”‚   â”œâ”€â”€ ensemble_comparison.csv
â”‚   â””â”€â”€ charts/                      # ìƒì„±ëœ ì°¨íŠ¸ë“¤
â”œâ”€â”€ Ensemble_Evaluation_Report.md   # í‰ê°€ ë³´ê³ ì„œ
â””â”€â”€ README.md                        # ì´ íŒŒì¼
```

## ì‚¬ìš© ë°©ë²•

### 1. ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡

```python
from RLQO.Ensemble_v1.ensemble_voting import VotingEnsemble

# Ensemble ìƒì„±
ensemble = VotingEnsemble(voting_strategy='weighted', verbose=True)
ensemble.load_models()

# ì˜ˆì¸¡
action, info = ensemble.predict(observation, query_type='CTE')
print(f"Selected action: {action}")
print(f"Model predictions: {info['predictions']}")
print(f"Confidences: {info['confidences']}")
```

### 2. í‰ê°€ ì‹¤í–‰ (ì²´í¬í¬ì¸íŠ¸ ì§€ì› ğŸ¯)

```bash
cd Apollo.ML/RLQO/Ensemble_v1/train
python ensemble_evaluate.py
```

**ì‹¤í–‰ ì •ë³´**:
- 5ê°€ì§€ ì „ëµ ëª¨ë‘ í‰ê°€
- ì•½ 1~2ì‹œê°„ ì†Œìš” ì˜ˆìƒ
- ê²°ê³¼: `results/ensemble_voting_results.json`, `results/ensemble_comparison.csv`

**ğŸ¯ ì²´í¬í¬ì¸íŠ¸ ê¸°ëŠ¥**:
- âœ… ìë™ ì €ì¥: ê° ì¿¼ë¦¬ ì™„ë£Œ í›„, 5 episodesë§ˆë‹¤
- âœ… ìë™ ì¬ê°œ: ì¤‘ë‹¨ í›„ ì¬ì‹¤í–‰ ì‹œ ì´ì–´ì„œ ì§„í–‰
- âœ… ì „ëµë³„ ì €ì¥: ê° ì „ëµë§ˆë‹¤ ë…ë¦½ì ì¸ ì²´í¬í¬ì¸íŠ¸
- âœ… ìœ„ì¹˜: `results/checkpoints/checkpoint_<strategy>.json`

**ì¤‘ë‹¨ í›„ ì¬ê°œ**:
1. Ctrl+Cë¡œ ì¤‘ë‹¨
2. ë™ì¼í•œ ëª…ë ¹ì–´ë¡œ ì¬ì‹¤í–‰ â†’ ìë™ìœ¼ë¡œ ì´ì–´ì„œ ì§„í–‰

**ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬**:
```bash
# ì²´í¬í¬ì¸íŠ¸ ëª©ë¡ ë° ì§„í–‰ë¥  í™•ì¸
python manage_checkpoints.py list

# íŠ¹ì • ì „ëµì˜ ìƒì„¸ ì •ë³´
python manage_checkpoints.py details weighted

# íŠ¹ì • ì „ëµì˜ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ (ì²˜ìŒë¶€í„° ì¬ì‹œì‘)
python manage_checkpoints.py delete weighted

# ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ
python manage_checkpoints.py delete-all
```

ë˜ëŠ” Pythonì—ì„œ:

```python
from RLQO.Ensemble_v1.train.ensemble_evaluate import evaluate_ensemble

results = evaluate_ensemble(
    voting_strategy='weighted',
    n_queries=30,
    n_episodes=10,
    verbose=True,
    resume=True  # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ
)
```

### 3. ì—¬ëŸ¬ ì „ëµ ë¹„êµ

```python
from RLQO.Ensemble_v1.train.ensemble_evaluate import compare_strategies

strategies = ['majority', 'weighted', 'equal', 'performance', 'query_type']
comparison_results = compare_strategies(
    strategies=strategies,
    n_queries=30,
    n_episodes=10
)
```

### 4. ì‹œê°í™” ìƒì„±

```bash
cd Apollo.ML/RLQO/Ensemble_v1
python visualize_ensemble.py
```

## í‰ê°€ ë©”íŠ¸ë¦­

1. **Mean Speedup**: í‰ê·  ì†ë„ í–¥ìƒë¥ 
2. **Median Speedup**: ì¤‘ì•™ê°’ ì†ë„ í–¥ìƒë¥ 
3. **Win Rate**: ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ê°œì„ ëœ ì¿¼ë¦¬ ë¹„ìœ¨
4. **Safe Rate**: ì„±ëŠ¥ ì €í•˜ê°€ 10% ì´ë‚´ì¸ ë¹„ìœ¨
5. **Model Agreement**: ëª¨ë¸ë“¤ì´ ì¼ì¹˜í•˜ëŠ” ì •ë„

## ì˜ˆìƒ ì„±ëŠ¥

- **ëª©í‘œ Mean Speedup**: 2.0~2.3x
- **í˜„ì¬ ìµœê³  ë‹¨ì¼ ëª¨ë¸**: DDPG v1 (1.88x)
- **ì˜ˆìƒ ê°œì„ **: 10~20% ì¶”ê°€ í–¥ìƒ
- **ì•ˆì •ì„±**: ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ ë¶„ì‚° ê°ì†Œ

## ì£¼ìš” íŠ¹ì§•

### 1. ë‹¤ì–‘ì„± (Diversity)
- Discrete (DQN, PPO) + Continuous (DDPG, SAC) ëª¨ë¸ ê²°í•©
- ì„œë¡œ ë‹¤ë¥¸ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì˜ ê°•ì  í™œìš©

### 2. ì ì‘ì„± (Adaptability)
- ì¿¼ë¦¬ íƒ€ì…ë³„ ìµœì  ëª¨ë¸ ì„ íƒ
- Confidence thresholdë¡œ ë¶ˆí™•ì‹¤í•œ ì˜ˆì¸¡ ì œì™¸

### 3. ê²¬ê³ ì„± (Robustness)
- ë‹¨ì¼ ëª¨ë¸ì˜ ì‹¤íŒ¨ì— ê°•í•¨
- ì—¬ëŸ¬ ëª¨ë¸ì˜ í•©ì˜ë¡œ ì•ˆì •ì  ì„±ëŠ¥

### 4. í•´ì„ ê°€ëŠ¥ì„± (Interpretability)
- ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ê³¼ confidence ì¶”ì 
- ëª¨ë¸ ê°„ í•©ì˜ë„ ë¶„ì„ ê°€ëŠ¥

## í•œê³„ì 

1. **ì¶”ë¡  ì‹œê°„**: 4ê°œ ëª¨ë¸ì„ ëª¨ë‘ ì‹¤í–‰í•˜ë¯€ë¡œ ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ ëŠë¦¼
2. **ë©”ëª¨ë¦¬ ì‚¬ìš©**: 4ê°œ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œí•´ì•¼ í•¨
3. **Continuous â†’ Discrete ë³€í™˜**: DDPG/SACì˜ ì—°ì† ì•¡ì…˜ì„ ì´ì‚° ì•¡ì…˜ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì—ì„œ ì •ë³´ ì†ì‹¤ ê°€ëŠ¥

## í–¥í›„ ê°œì„  ë°©í–¥

1. **Meta-Learning**: ì¿¼ë¦¬ íŠ¹ì„±ì— ë”°ë¼ ìë™ìœ¼ë¡œ ìµœì  ëª¨ë¸ ì„ íƒ
2. **Multi-Agent**: ìˆœì°¨ì ìœ¼ë¡œ ì—¬ëŸ¬ ëª¨ë¸ì´ í˜‘ë ¥í•˜ì—¬ ìµœì í™”
3. **Online Learning**: ì‹¤ì‹œê°„ í”¼ë“œë°±ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ë™ì  ì¡°ì •
4. **Model Distillation**: 4ê°œ ëª¨ë¸ì˜ ì§€ì‹ì„ 1ê°œì˜ ê²½ëŸ‰ ëª¨ë¸ë¡œ ì••ì¶•

## ì°¸ê³  ìë£Œ

- DQN v3 í‰ê°€ ë³´ê³ ì„œ: `Apollo.ML/RLQO/DQN_v3/DQN_v3_Evaluation_Report.md`
- PPO v3 í‰ê°€ ë³´ê³ ì„œ: `Apollo.ML/RLQO/PPO_v3/PPO_v3_Evaluation_Report.md`
- DDPG v1 í‰ê°€ ë³´ê³ ì„œ: `Apollo.ML/RLQO/DDPG_v1/DDPG_v1_Evaluation_Report.md`
- SAC v1 í‰ê°€ ë³´ê³ ì„œ: `Apollo.ML/RLQO/SAC_v1/SAC_v1_Evaluation_Report.md`
- ëª¨ë¸ ë¹„êµ: `Apollo.ML/RLQO/Initial_Model_Comparison.md`

## ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” Apollo í”„ë¡œì íŠ¸ì˜ ì¼ë¶€ì…ë‹ˆë‹¤.

