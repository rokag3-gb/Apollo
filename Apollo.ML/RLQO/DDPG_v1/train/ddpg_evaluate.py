# -*- coding: utf-8 -*-
"""
DDPG v1 Evaluation Script

í•™ìŠµëœ DDPG ëª¨ë¸ì„ í‰ê°€í•˜ê³  DQN v3, PPO v3ì™€ ë¹„êµí•©ë‹ˆë‹¤.
"""

import os
import sys
import argparse
import json
from datetime import datetime
import numpy as np
import pandas as pd

from stable_baselines3 import DDPG

# Project root path setup
current_file_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_file_dir, '..', '..', '..', '..'))
apollo_ml_dir = os.path.join(project_root, 'Apollo.ML')

sys.path.insert(0, project_root)
sys.path.insert(0, apollo_ml_dir)

from RLQO.DDPG_v1.env.ddpg_db_env import QueryPlanRealDBEnvDDPGv1

# Load 30 queries
sys.path.insert(0, os.path.join(apollo_ml_dir, 'RLQO'))
from constants2 import SAMPLE_QUERIES

# Query names mapping
QUERY_NAMES = {
    0: 'ê³„ì¢Œë³„ ì¼ë³„ ê±°ë˜ í†µê³„',
    1: 'ê±°ë˜ì†Œë³„ ì¢…ëª©ë³„ í‰ê·  ì²´ê²°ê°€ê²©ê³¼ ê±°ë˜ëŸ‰',
    2: 'ëŒ€ìš©ëŸ‰ í…Œì´ë¸” ì „ì²´ ìŠ¤ìº”',
    3: '2-way JOIN (ëŒ€ìš©ëŸ‰)',
    4: '3-way JOIN + ORDER BY',
    5: 'NOT EXISTS (ì„œë¸Œì¿¼ë¦¬)',
    6: 'RAND() í•¨ìˆ˜',
    7: 'ì£¼ë¬¸ ì²´ê²°ë¥ ê³¼ í‰ê·  ìŠ¬ë¦¬í”¼ì§€ ë¶„ì„',
    8: 'í¬ì§€ì…˜ ìˆ˜ìµë¥  ë¶„ì„',
    9: 'ë‹¹ì¼ ê±°ë˜ëŸ‰ ìƒìœ„ ì¢…ëª©',
    10: 'ë‹¹ì¼ ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ ì¢…ëª©',
    11: 'ì „ì¼ ì¢…ê°€ ëŒ€ë¹„ ë“±ë½ë¥  ìƒìœ„ ì¢…ëª©',
    12: 'ê³„ì¢Œë³„ í¬ì§€ì…˜ í‰ê°€',
    13: 'ë¯¸ì²´ê²° ì£¼ë¬¸ ëª©ë¡',
    14: 'ìµœê·¼ ëŒ€ëŸ‰ ì£¼ë¬¸ ê²€ìƒ‰',
    15: 'ìµœê·¼ ê±°ë˜ ëª¨ë‹ˆí„°ë§',
    16: 'ì£¼ë¬¸ê³¼ ì²´ê²° ë‚´ì—­ í•¨ê»˜ ì¡°íšŒ',
    17: 'ì²´ê²° ë‚´ì—­ì´ ìˆëŠ” ì£¼ë¬¸ë§Œ ì¡°íšŒ (EXISTS)',
    18: 'ì²´ê²° ë‚´ì—­ì´ ìˆëŠ” ì£¼ë¬¸ë§Œ ì¡°íšŒ (IN)',
    19: 'ê³„ì¢Œë³„ í˜„ê¸ˆ ì”ì•¡ ì¡°íšŒ',
    20: 'ê±°ë˜ì†Œë³„ ì¢…ëª© ìˆ˜ ë° í†µê³„',
    21: 'ì¢…ëª©ë³„ ìµœê·¼ ê°€ê²© ì´ë ¥',
    22: 'ê³ ê°ë³„ ê³„ì¢Œ ë° ì”ì•¡ ìš”ì•½',
    23: 'ë¦¬ìŠ¤í¬ ë…¸ì¶œë„ ìŠ¤ëƒ…ìƒ· ì¡°íšŒ',
    24: 'ê³„ì¢Œë³„ ì£¼ë¬¸ ì†ŒìŠ¤ ë¶„í¬',
    25: 'ì¢…ëª© íƒ€ì…ë³„ ê±°ë˜ í†µê³„',
    26: 'ë§ˆì§„ ê³„ì¢Œ ìƒíƒœ ì¡°íšŒ',
    27: 'ì»´í”Œë¼ì´ì–¸ìŠ¤ ê²½ê³  í˜„í™©',
    28: 'ê±°ë˜ ì›ì¥ ì§‘ê³„ vs í¬ì§€ì…˜ ê²€ì¦',
    29: 'ì¢…ëª©ë³„ ì‹œì„¸ ë³€ë™ì„± ë¶„ì„'
}


def evaluate_ddpg(model_path: str, episodes: int = 3, output_file: str = None):
    """
    DDPG ëª¨ë¸ í‰ê°€
    
    Args:
        model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
        episodes: í‰ê°€ ì—í”¼ì†Œë“œ ìˆ˜
        output_file: ê²°ê³¼ ì €ì¥ ê²½ë¡œ (JSON)
    """
    print("=" * 80)
    print(" DDPG v1 Model Evaluation")
    print("=" * 80)
    print(f"Model: {model_path}")
    print(f"Episodes: {episodes}")
    print(f"Queries: {len(SAMPLE_QUERIES)}")
    print("=" * 80)
    
    # Check model exists
    if not os.path.exists(model_path):
        print(f"[ERROR] Model not found: {model_path}")
        return
    
    # Load model
    print("\n[1/3] Loading model...")
    try:
        model = DDPG.load(model_path)
        print(f"âœ“ Model loaded successfully")
    except Exception as e:
        print(f"[ERROR] Failed to load model: {e}")
        return
    
    # Create environment
    print("\n[2/3] Creating evaluation environment...")
    env = QueryPlanRealDBEnvDDPGv1(
        query_list=SAMPLE_QUERIES,
        max_steps=10,
        timeout_seconds=30,
        verbose=False  # Reduce verbosity during evaluation
    )
    print(f"âœ“ Environment created")
    
    # Evaluation
    print("\n[3/3] Starting evaluation...")
    print("-" * 80)
    
    results = []
    query_results = {i: [] for i in range(len(SAMPLE_QUERIES))}
    
    for episode in range(episodes):
        print(f"\nEpisode {episode + 1}/{episodes}")
        print("-" * 80)
        
        for query_idx in range(len(SAMPLE_QUERIES)):
            # Reset to specific query
            env.current_query_ix = query_idx
            obs, info = env.reset()
            
            baseline_time = info['baseline_time']
            best_time = baseline_time
            best_action = None
            total_reward = 0.0
            
            # Run episode
            for step in range(10):
                # Use deterministic action (no noise)
                action, _ = model.predict(obs, deterministic=True)
                
                obs, reward, terminated, truncated, info = env.step(action)
                total_reward += reward
                
                if info['current_time'] < best_time:
                    best_time = info['current_time']
                    best_action = info['action_description']
                
                if terminated or truncated:
                    break
            
            speedup = baseline_time / best_time if best_time > 0 else 1.0
            
            result = {
                'episode': episode + 1,
                'query_idx': query_idx,
                'query_name': QUERY_NAMES.get(query_idx, f'Query {query_idx}'),
                'baseline_time_ms': baseline_time,
                'best_time_ms': best_time,
                'speedup': speedup,
                'improvement_pct': (speedup - 1.0) * 100,
                'total_reward': total_reward,
                'best_action': best_action
            }
            
            results.append(result)
            query_results[query_idx].append(speedup)
            
            # ì¶œë ¥ í˜•ì‹ ê°œì„ 
            query_name = QUERY_NAMES.get(query_idx, f'Query {query_idx}')
            action_str = best_action if best_action else 'NO_ACTION'
            print(f"  Query {query_idx:2d} [{query_name[:30]:30s}]: "
                  f"{baseline_time:6.1f}ms â†’ {best_time:6.1f}ms "
                  f"(Speedup: {speedup:.3f}x, {(speedup-1)*100:+.1f}%)")
            if best_action:
                print(f"           Action: {action_str}")
    
    env.close()
    
    # Analysis
    print("\n" + "=" * 80)
    print(" Evaluation Results Summary")
    print("=" * 80)
    
    df = pd.DataFrame(results)
    
    # Overall statistics
    print(f"\nì „ì²´ í†µê³„ ({episodes} episodes Ã— {len(SAMPLE_QUERIES)} queries):")
    print(f"  - í‰ê·  Speedup: {df['speedup'].mean():.3f}x")
    print(f"  - ì¤‘ì•™ê°’ Speedup: {df['speedup'].median():.3f}x")
    print(f"  - ìµœëŒ€ Speedup: {df['speedup'].max():.3f}x")
    print(f"  - ìµœì†Œ Speedup: {df['speedup'].min():.3f}x")
    print(f"  - í‘œì¤€í¸ì°¨: {df['speedup'].std():.3f}")
    print(f"  - í‰ê·  ê°œì„ : {df['improvement_pct'].mean():+.2f}%")
    print(f"  - í‰ê·  Reward: {df['total_reward'].mean():.4f}")
    
    # Performance categories
    excellent = df[df['speedup'] >= 1.5]
    good = df[(df['speedup'] >= 1.2) & (df['speedup'] < 1.5)]
    neutral = df[(df['speedup'] >= 0.9) & (df['speedup'] < 1.2)]
    degraded = df[df['speedup'] < 0.9]
    
    print(f"\nì„±ëŠ¥ ë¶„í¬:")
    print(f"  - íƒì›” (â‰¥1.5x): {len(excellent)} ({len(excellent)/len(df)*100:.1f}%)")
    print(f"  - ì–‘í˜¸ (1.2~1.5x): {len(good)} ({len(good)/len(df)*100:.1f}%)")
    print(f"  - ì¤‘ë¦½ (0.9~1.2x): {len(neutral)} ({len(neutral)/len(df)*100:.1f}%)")
    print(f"  - ì €í•˜ (<0.9x): {len(degraded)} ({len(degraded)/len(df)*100:.1f}%)")
    
    # Query-wise statistics
    print(f"\nì¿¼ë¦¬ë³„ í‰ê·  ì„±ëŠ¥ (ì¿¼ë¦¬ ì´ë¦„ ë° ì•¡ì…˜ í¬í•¨):")
    print(f"{'='*120}")
    query_summary = []
    
    # ê° ì¿¼ë¦¬ì˜ ëŒ€í‘œ ì•¡ì…˜ ì°¾ê¸° (ì²« ë²ˆì§¸ ì—í”¼ì†Œë“œì—ì„œ)
    query_actions = {}
    for result in results:
        if result['episode'] == 1:
            query_actions[result['query_idx']] = result['best_action']
    
    for query_idx in range(len(SAMPLE_QUERIES)):
        query_speedups = query_results[query_idx]
        avg_speedup = np.mean(query_speedups)
        std_speedup = np.std(query_speedups)
        improvement_pct = (avg_speedup - 1.0) * 100
        
        query_summary.append({
            'query_idx': query_idx,
            'query_name': QUERY_NAMES.get(query_idx, f'Query {query_idx}'),
            'avg_speedup': avg_speedup,
            'std_speedup': std_speedup,
            'improvement_pct': improvement_pct,
            'action': query_actions.get(query_idx, 'NO_ACTION')
        })
        
        query_name = QUERY_NAMES.get(query_idx, f'Query {query_idx}')
        action_str = query_actions.get(query_idx, None)
        
        # ì„±ëŠ¥ ì•„ì´ì½˜
        if avg_speedup >= 2.0:
            icon = 'ğŸš€'
        elif avg_speedup >= 1.2:
            icon = 'âœ…'
        elif avg_speedup >= 0.9:
            icon = '  '
        else:
            icon = 'âš ï¸'
        
        print(f"{icon} Query {query_idx:2d} [{query_name[:35]:35s}]: "
              f"{avg_speedup:6.3f}x Â± {std_speedup:.3f} ({improvement_pct:+6.1f}%)")
        
        if action_str and action_str != 'NO_ACTION':
            # ì•¡ì…˜ ë¬¸ìì—´ ì¤„ë°”ê¿ˆ ì²˜ë¦¬
            if len(action_str) > 100:
                print(f"           Action: {action_str[:100]}...")
                print(f"                   {action_str[100:]}")
            else:
                print(f"           Action: {action_str}")
    
    print(f"{'='*120}")
    
    # Top 5 best queries
    print(f"\nìƒìœ„ 5ê°œ ì¿¼ë¦¬ (í‰ê·  Speedup):")
    top_queries = sorted(query_summary, key=lambda x: x['avg_speedup'], reverse=True)[:5]
    for i, q in enumerate(top_queries, 1):
        query_name = q['query_name']
        action_str = q['action'] if q['action'] and q['action'] != 'NO_ACTION' else 'NO_ACTION'
        print(f"  {i}. Query {q['query_idx']:2d} [{query_name[:30]:30s}]: {q['avg_speedup']:.3f}x ({q['improvement_pct']:+.1f}%)")
        if action_str != 'NO_ACTION':
            print(f"      â†’ {action_str}")
    
    # Top 5 worst queries
    print(f"\ní•˜ìœ„ 5ê°œ ì¿¼ë¦¬ (í‰ê·  Speedup):")
    worst_queries = sorted(query_summary, key=lambda x: x['avg_speedup'])[:5]
    for i, q in enumerate(worst_queries, 1):
        query_name = q['query_name']
        action_str = q['action'] if q['action'] and q['action'] != 'NO_ACTION' else 'NO_ACTION'
        print(f"  {i}. Query {q['query_idx']:2d} [{query_name[:30]:30s}]: {q['avg_speedup']:.3f}x ({q['improvement_pct']:+.1f}%)")
    
    # ì•¡ì…˜ì´ ì ìš©ëœ ì¿¼ë¦¬ ìš”ì•½
    print(f"\nì•¡ì…˜ì´ ì ìš©ëœ ì¿¼ë¦¬ ìš”ì•½:")
    action_applied = [q for q in query_summary if q['action'] and q['action'] != 'NO_ACTION']
    if action_applied:
        print(f"ì´ {len(action_applied)}ê°œ ì¿¼ë¦¬ì— ìµœì í™” ì ìš©:")
        for q in sorted(action_applied, key=lambda x: x['avg_speedup'], reverse=True):
            print(f"  â€¢ Query {q['query_idx']:2d} [{q['query_name'][:30]:30s}]: {q['avg_speedup']:.3f}x")
            print(f"    â†’ {q['action']}")
    else:
        print(f"  (ì•¡ì…˜ì´ ì ìš©ëœ ì¿¼ë¦¬ ì—†ìŒ)")
    
    # Save results
    if output_file:
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (ìƒëŒ€ ê²½ë¡œ ì…ë ¥ ì‹œ í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
        output_file = os.path.abspath(output_file)
        
        output_data = {
            'timestamp': datetime.now().isoformat(),
            'model_path': model_path,
            'episodes': episodes,
            'overall': {
                'mean_speedup': float(df['speedup'].mean()),
                'median_speedup': float(df['speedup'].median()),
                'max_speedup': float(df['speedup'].max()),
                'min_speedup': float(df['speedup'].min()),
                'std_speedup': float(df['speedup'].std()),
                'mean_improvement_pct': float(df['improvement_pct'].mean())
            },
            'distribution': {
                'excellent': len(excellent),
                'good': len(good),
                'neutral': len(neutral),
                'degraded': len(degraded)
            },
            'query_summary': query_summary,
            'detailed_results': results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ“ Results saved to: {output_file}")
    
    print("\n" + "=" * 80)
    print(" Evaluation Complete")
    print("=" * 80)
    
    return df


def main():
    parser = argparse.ArgumentParser(description='DDPG v1 Model Evaluation')
    parser.add_argument(
        '--model',
        type=str,
        default='Apollo.ML/artifacts/RLQO/models/ddpg_v1_realdb_50k.zip',
        help='Path to trained model'
    )
    parser.add_argument(
        '--episodes',
        type=int,
        default=3,
        help='Number of evaluation episodes'
    )
    parser.add_argument(
        '--output',
        type=str,
        default=None,
        help='Output file path (JSON)'
    )
    
    args = parser.parse_args()
    
    # Default output file
    if args.output is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        args.output = f"ddpg_v1_eval_{timestamp}.json"
    
    evaluate_ddpg(args.model, args.episodes, args.output)


if __name__ == '__main__':
    main()

