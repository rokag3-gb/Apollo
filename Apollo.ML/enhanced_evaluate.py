# -*- coding: utf-8 -*-
"""
íšŒê·€ ëª¨ë¸ í‰ê°€ ëª¨ë“ˆ
ë‹¤ì–‘í•œ íšŒê·€ í‰ê°€ ë©”íŠ¸ë¦­ê³¼ ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    mean_squared_error, mean_absolute_error, r2_score,
    mean_absolute_percentage_error, median_absolute_error,
    explained_variance_score, max_error
)
from sklearn.model_selection import cross_val_score, TimeSeriesSplit, train_test_split
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

def load_model_and_data():
    """ì €ì¥ëœ ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        model = joblib.load('artifacts/model.joblib')
        scaler = joblib.load('artifacts/scaler.joblib')
        
        # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ëœ ë°ì´í„° ë¡œë“œ
        df_preprocessed = pd.read_parquet('artifacts/enhanced_features.parquet')
        
        # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬ (ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ)
        numeric_cols = df_preprocessed.select_dtypes(include=[np.number]).columns.tolist()
        feature_cols = [col for col in numeric_cols if col not in ['plan_id', 'query_id', 'last_ms']]
        
        # ë¬¸ìì—´ ì»¬ëŸ¼ ì œì™¸ (ìŠ¤ì¼€ì¼ë§í•  ìˆ˜ ì—†ìŒ)
        string_cols = df_preprocessed.select_dtypes(include=['object']).columns.tolist()
        feature_cols = [col for col in feature_cols if col not in string_cols]
        
        X_processed = df_preprocessed[feature_cols]
        y_processed = df_preprocessed['last_ms']
        
        feature_importance = pd.read_csv('artifacts/model_importance.csv')
        
        # í›ˆë ¨ ì‹œì™€ ë™ì¼í•œ ë¶„í•  ì ìš© (random_state=42)
        X_train, X_val, y_train, y_val = train_test_split(
            X_processed, y_processed, test_size=0.2, random_state=42
        )
        
        print("ëª¨ë¸ê³¼ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print(f"í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ëœ ë°ì´í„° í¬ê¸°: {df_preprocessed.shape}")
        print(f"í›ˆë ¨ ë°ì´í„° í¬ê¸°: {X_train.shape}")
        print(f"ê²€ì¦ ë°ì´í„° í¬ê¸°: {X_val.shape}")
        
        return model, scaler, X_train, X_val, y_train, y_val, feature_importance
    except Exception as e:
        print(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None, None, None, None, None, None

def calculate_regression_metrics(y_true, y_pred):
    """íšŒê·€ ëª¨ë¸ì„ ìœ„í•œ ë‹¤ì–‘í•œ í‰ê°€ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    
    # ê¸°ë³¸ ë©”íŠ¸ë¦­
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    
    # ì¶”ê°€ ë©”íŠ¸ë¦­
    mape = mean_absolute_percentage_error(y_true, y_pred) * 100
    medae = median_absolute_error(y_true, y_pred)
    evs = explained_variance_score(y_true, y_pred)
    max_err = max_error(y_true, y_pred)
    
    # MAPE ëŒ€ì•ˆ (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
    mape_alt = np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-8))) * 100
    
    # ìƒëŒ€ì  ì˜¤ì°¨
    relative_error = np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-8)))
    
    # ëŒ€ì¹­ MAPE (Symmetric MAPE)
    smape = np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred) + 1e-8)) * 100
    
    # Mean Absolute Scaled Error (MASE) - ì‹œê³„ì—´ ë°ì´í„°ìš©
    naive_forecast_error = np.mean(np.abs(np.diff(y_true)))
    mase = mae / (naive_forecast_error + 1e-8)
    
    # ì”ì°¨ í†µê³„
    residuals = y_true - y_pred
    residual_std = np.std(residuals)
    residual_mean = np.mean(residuals)
    
    # ì •ê·œì„± ê²€ì • (Shapiro-Wilk)
    if len(residuals) <= 5000:  # ìƒ˜í”Œ í¬ê¸° ì œí•œ
        shapiro_stat, shapiro_p = stats.shapiro(residuals)
    else:
        shapiro_stat, shapiro_p = np.nan, np.nan
    
    return {
        'mse': mse,
        'rmse': rmse,
        'mae': mae,
        'r2': r2,
        'mape': mape,
        'mape_alt': mape_alt,
        'medae': medae,
        'evs': evs,
        'max_error': max_err,
        'relative_error': relative_error,
        'smape': smape,
        'mase': mase,
        'residual_std': residual_std,
        'residual_mean': residual_mean,
        'shapiro_stat': shapiro_stat,
        'shapiro_p': shapiro_p
    }

def evaluate_model_performance(model, scaler, X, y, feature_cols, data_type=""):
    """ëª¨ë¸ ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤."""
    
    print(f"=== {data_type} ë°ì´í„° ì„±ëŠ¥ í‰ê°€ ===")
    
    # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
    X_scaled = scaler.transform(X)
    
    # ì˜ˆì¸¡
    y_pred = model.predict(X_scaled)
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    metrics = calculate_regression_metrics(y, y_pred)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š ê¸°ë³¸ ë©”íŠ¸ë¦­:")
    print(f"  RMSE: {metrics['rmse']:.2f}")
    print(f"  MAE: {metrics['mae']:.2f}")
    print(f"  RÂ²: {metrics['r2']:.4f}")
    print(f"  EVS: {metrics['evs']:.4f}")
    
    print(f"\nğŸ“ˆ ì˜¤ì°¨ ë¶„ì„:")
    print(f"  MAPE: {metrics['mape']:.2f}%")
    print(f"  MAPE (ëŒ€ì•ˆ): {metrics['mape_alt']:.2f}%")
    print(f"  SMAPE: {metrics['smape']:.2f}%")
    print(f"  MASE: {metrics['mase']:.4f}")
    print(f"  ìƒëŒ€ ì˜¤ì°¨: {metrics['relative_error']:.4f}")
    
    print(f"\nğŸ“‹ ë¶„í¬ ë¶„ì„:")
    print(f"  ì¤‘ì•™ê°’ ì ˆëŒ€ ì˜¤ì°¨: {metrics['medae']:.2f}")
    print(f"  ìµœëŒ€ ì˜¤ì°¨: {metrics['max_error']:.2f}")
    print(f"  ì”ì°¨ í‰ê· : {metrics['residual_mean']:.2f}")
    print(f"  ì”ì°¨ í‘œì¤€í¸ì°¨: {metrics['residual_std']:.2f}")
    
    # ì •ê·œì„± ê²€ì • ê²°ê³¼
    if not np.isnan(metrics['shapiro_p']):
        print(f"\nğŸ” ì •ê·œì„± ê²€ì • (Shapiro-Wilk):")
        print(f"  í†µê³„ëŸ‰: {metrics['shapiro_stat']:.4f}")
        print(f"  p-value: {metrics['shapiro_p']:.4f}")
        if metrics['shapiro_p'] > 0.05:
            print("  âœ… ì”ì°¨ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¦„ (p > 0.05)")
        else:
            print("  âŒ ì”ì°¨ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•ŠìŒ (p â‰¤ 0.05)")
    
    return metrics, y_pred

def analyze_performance_by_ranges(y_true, y_pred):
    """ì„±ëŠ¥ì„ êµ¬ê°„ë³„ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    print(f"\n=== ì„±ëŠ¥ êµ¬ê°„ë³„ ë¶„ì„ ===")
    
    # êµ¬ê°„ ì •ì˜
    ranges = [
        (0, 1, "1ms ë¯¸ë§Œ"),
        (1, 10, "1-10ms"),
        (10, 100, "10-100ms"),
        (100, 1000, "100ms-1s"),
        (1000, float('inf'), "1s ì´ìƒ")
    ]
    
    for min_val, max_val, label in ranges:
        if max_val == float('inf'):
            mask = y_true >= min_val
        else:
            mask = (y_true >= min_val) & (y_true < max_val)
        
        if mask.sum() > 0:
            subset_y_true = y_true[mask]
            subset_y_pred = y_pred[mask]
            
            subset_r2 = r2_score(subset_y_true, subset_y_pred)
            subset_mae = mean_absolute_error(subset_y_true, subset_y_pred)
            subset_mape = np.mean(np.abs((subset_y_true - subset_y_pred) / np.maximum(subset_y_true, 1e-8))) * 100
            
            print(f"  {label}: RÂ²={subset_r2:.4f}, MAE={subset_mae:.2f}, MAPE={subset_mape:.2f}% (n={mask.sum()})")

def cross_validation_analysis(model, scaler, X, y, cv_folds=5):
    """êµì°¨ ê²€ì¦ì„ í†µí•œ ëª¨ë¸ ì•ˆì •ì„± ë¶„ì„"""
    
    print(f"\n=== êµì°¨ ê²€ì¦ ë¶„ì„ ({cv_folds}-fold) ===")
    
    # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
    X_scaled = scaler.transform(X)
    
    # ì‹œê³„ì—´ ë¶„í•  (ë°ì´í„°ê°€ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
    tscv = TimeSeriesSplit(n_splits=cv_folds)
    
    # RÂ² ì ìˆ˜ ê³„ì‚°
    r2_scores = cross_val_score(model, X_scaled, y, cv=tscv, scoring='r2')
    mse_scores = -cross_val_score(model, X_scaled, y, cv=tscv, scoring='neg_mean_squared_error')
    mae_scores = -cross_val_score(model, X_scaled, y, cv=tscv, scoring='neg_mean_absolute_error')
    
    print(f"RÂ² ì ìˆ˜: {r2_scores.mean():.4f} Â± {r2_scores.std():.4f}")
    print(f"RMSE: {np.sqrt(mse_scores.mean()):.2f} Â± {np.sqrt(mse_scores.std()):.2f}")
    print(f"MAE: {mae_scores.mean():.2f} Â± {mae_scores.std():.2f}")
    
    # ì•ˆì •ì„± í‰ê°€
    cv_std = r2_scores.std()
    if cv_std < 0.01:
        stability = "ğŸŸ¢ ë§¤ìš° ì•ˆì •ì "
    elif cv_std < 0.05:
        stability = "ğŸŸ¡ ì•ˆì •ì "
    else:
        stability = "ğŸŸ  ë¶ˆì•ˆì •"
    
    print(f"ì•ˆì •ì„±: {stability} (CV std: {cv_std:.4f})")
    
    return {
        'r2_scores': r2_scores,
        'mse_scores': mse_scores,
        'mae_scores': mae_scores,
        'cv_std': cv_std
    }

def analyze_feature_importance(feature_importance, top_n=15):
    """í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„"""
    
    print(f"\n=== í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ (ìƒìœ„ {top_n}ê°œ) ===")
    
    top_features = feature_importance.head(top_n)
    
    for idx, row in top_features.iterrows():
        print(f"  {idx+1:2d}. {row['feature']:<25} : {row['importance']:.4f}")
    
    # ì¤‘ìš”ë„ ë¶„í¬ ë¶„ì„
    total_importance = feature_importance['importance'].sum()
    top_n_importance = top_features['importance'].sum()
    coverage = (top_n_importance / total_importance) * 100
    
    print(f"\nìƒìœ„ {top_n}ê°œ í”¼ì²˜ì˜ ì¤‘ìš”ë„ ë¹„ìœ¨: {coverage:.1f}%")

def residual_analysis(y_true, y_pred):
    """ì”ì°¨ ë¶„ì„"""
    
    print(f"\n=== ì”ì°¨ ë¶„ì„ ===")
    
    residuals = y_true - y_pred
    
    # ì”ì°¨ í†µê³„
    print(f"ì”ì°¨ í‰ê· : {residuals.mean():.4f}")
    print(f"ì”ì°¨ í‘œì¤€í¸ì°¨: {residuals.std():.4f}")
    print(f"ì”ì°¨ ìµœì†Ÿê°’: {residuals.min():.4f}")
    print(f"ì”ì°¨ ìµœëŒ“ê°’: {residuals.max():.4f}")
    
    # ì´ìƒì¹˜ íƒì§€ (IQR ë°©ë²•)
    Q1 = residuals.quantile(0.25)
    Q3 = residuals.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    outliers = residuals[(residuals < lower_bound) | (residuals > upper_bound)]
    outlier_ratio = len(outliers) / len(residuals) * 100
    
    print(f"ì´ìƒì¹˜ ë¹„ìœ¨: {outlier_ratio:.2f}% ({len(outliers)}/{len(residuals)})")
    
    # ì”ì°¨ì™€ ì˜ˆì¸¡ê°’ì˜ ìƒê´€ê´€ê³„ (Heteroscedasticity ì²´í¬)
    correlation = np.corrcoef(residuals, y_pred)[0, 1]
    print(f"ì”ì°¨-ì˜ˆì¸¡ê°’ ìƒê´€ê´€ê³„: {correlation:.4f}")
    
    if abs(correlation) > 0.3:
        print("  âš ï¸  ì´ë¶„ì‚°ì„± ì˜ì‹¬ (ìƒê´€ê´€ê³„ > 0.3)")
    else:
        print("  âœ… ë“±ë¶„ì‚°ì„± ê°€ì • ë§Œì¡±")

def model_quality_assessment(metrics, cv_results=None):
    """ëª¨ë¸ í’ˆì§ˆ ì¢…í•© í‰ê°€"""
    
    print(f"\n=== ëª¨ë¸ í’ˆì§ˆ ì¢…í•© í‰ê°€ ===")
    
    # RÂ² ê¸°ë°˜ ì„±ëŠ¥ í‰ê°€
    r2 = metrics['r2']
    if r2 >= 0.9:
        performance = "ğŸŸ¢ ìš°ìˆ˜í•œ ì„±ëŠ¥"
    elif r2 >= 0.7:
        performance = "ğŸŸ¡ ì–‘í˜¸í•œ ì„±ëŠ¥"
    elif r2 >= 0.5:
        performance = "ğŸŸ  ë³´í†µ ì„±ëŠ¥"
    else:
        performance = "ğŸ”´ ë‚®ì€ ì„±ëŠ¥"
    
    print(f"ì„±ëŠ¥: {performance} (RÂ² = {r2:.4f})")
    
    # ì •í™•ë„ í‰ê°€ (MAPE ê¸°ì¤€)
    mape = metrics['mape_alt']
    if mape < 10:
        accuracy = "ğŸŸ¢ ë§¤ìš° ì •í™•"
    elif mape < 20:
        accuracy = "ğŸŸ¡ ì •í™•"
    elif mape < 50:
        accuracy = "ğŸŸ  ë³´í†µ"
    else:
        accuracy = "ğŸ”´ ë¶€ì •í™•"
    
    print(f"ì •í™•ë„: {accuracy} (MAPE = {mape:.2f}%)")
    
    # ì•ˆì •ì„± í‰ê°€
    if cv_results and 'cv_std' in cv_results:
        cv_std = cv_results['cv_std']
        if cv_std < 0.01:
            stability = "ğŸŸ¢ ë§¤ìš° ì•ˆì •ì "
        elif cv_std < 0.05:
            stability = "ğŸŸ¡ ì•ˆì •ì "
        else:
            stability = "ğŸŸ  ë¶ˆì•ˆì •"
        print(f"ì•ˆì •ì„±: {stability} (CV std = {cv_std:.4f})")
    
    # í¸í–¥ì„± í‰ê°€
    residual_mean = abs(metrics['residual_mean'])
    if residual_mean < 1:
        bias = "ğŸŸ¢ í¸í–¥ ì—†ìŒ"
    elif residual_mean < 10:
        bias = "ğŸŸ¡ ê²½ë¯¸í•œ í¸í–¥"
    else:
        bias = "ğŸŸ  í¸í–¥ ìˆìŒ"
    
    print(f"í¸í–¥ì„±: {bias} (ì”ì°¨ í‰ê·  = {metrics['residual_mean']:.2f})")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("=== íšŒê·€ ëª¨ë¸ í‰ê°€ ì‹œì‘ ===")
    
    # ëª¨ë¸ê³¼ ë°ì´í„° ë¡œë“œ (í›ˆë ¨/ê²€ì¦ ë¶„í•  í¬í•¨)
    model, scaler, X_train, X_val, y_train, y_val, feature_importance = load_model_and_data()
    
    if model is None:
        print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. ë¨¼ì € enhanced_train.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # í”¼ì²˜ ì»¬ëŸ¼ëª… ì¶”ì¶œ
    feature_cols = X_train.columns.tolist()
    
    # í›ˆë ¨ ë°ì´í„° ì„±ëŠ¥ í‰ê°€
    print("\n" + "="*60)
    metrics_train, y_pred_train = evaluate_model_performance(
        model, scaler, X_train, y_train, feature_cols, "í›ˆë ¨"
    )
    
    # ê²€ì¦ ë°ì´í„° ì„±ëŠ¥ í‰ê°€
    print("\n" + "="*60)
    metrics_val, y_pred_val = evaluate_model_performance(
        model, scaler, X_val, y_val, feature_cols, "ê²€ì¦"
    )
    
    # í›ˆë ¨/ê²€ì¦ ì„±ëŠ¥ ë¹„êµ
    print(f"\n=== í›ˆë ¨ vs ê²€ì¦ ì„±ëŠ¥ ë¹„êµ ===")
    print(f"RÂ² ì ìˆ˜: í›ˆë ¨={metrics_train['r2']:.4f}, ê²€ì¦={metrics_val['r2']:.4f}")
    print(f"RMSE: í›ˆë ¨={metrics_train['rmse']:.2f}, ê²€ì¦={metrics_val['rmse']:.2f}")
    print(f"MAE: í›ˆë ¨={metrics_train['mae']:.2f}, ê²€ì¦={metrics_val['mae']:.2f}")
    
    # Overfitting ì²´í¬
    r2_gap = abs(metrics_train['r2'] - metrics_val['r2'])
    if r2_gap < 0.05:
        print(f"âœ… Overfitting ì—†ìŒ (RÂ² ì°¨ì´: {r2_gap:.4f})")
    elif r2_gap < 0.1:
        print(f"âš ï¸  ê²½ë¯¸í•œ Overfitting (RÂ² ì°¨ì´: {r2_gap:.4f})")
    else:
        print(f"âŒ Overfitting ì˜ì‹¬ (RÂ² ì°¨ì´: {r2_gap:.4f})")
    
    # êµ¬ê°„ë³„ ì„±ëŠ¥ ë¶„ì„ (ê²€ì¦ ë°ì´í„° ê¸°ì¤€)
    analyze_performance_by_ranges(y_val, y_pred_val)
    
    # êµì°¨ ê²€ì¦ ë¶„ì„ (í›ˆë ¨ ë°ì´í„° ê¸°ì¤€)
    cv_results = cross_validation_analysis(model, scaler, X_train, y_train)
    
    # í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
    analyze_feature_importance(feature_importance)
    
    # ì”ì°¨ ë¶„ì„ (ê²€ì¦ ë°ì´í„° ê¸°ì¤€)
    residual_analysis(y_val, y_pred_val)
    
    # ëª¨ë¸ í’ˆì§ˆ ì¢…í•© í‰ê°€ (ê²€ì¦ ë°ì´í„° ê¸°ì¤€)
    model_quality_assessment(metrics_val, cv_results)
    
    print(f"\n=== í‰ê°€ ì™„ë£Œ ===")
    print(f"ìƒì„¸í•œ ë¶„ì„ ê²°ê³¼ê°€ ì¶œë ¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ëª¨ë¸ ì„±ëŠ¥ì„ ê°œì„ í•˜ë ¤ë©´ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ì´ë‚˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ê³ ë ¤í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
